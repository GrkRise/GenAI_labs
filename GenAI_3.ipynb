{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6zOYRsCb5OdMfK7uNnQNz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GrkRise/GenAI_labs/blob/main/GenAI_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Лекция 2: \"Агент-Аналитик\" - Практическая работа\n",
        "\n",
        "Этот ноутбук содержит полный код для создания \"Агента-Аналитика\" с использованием `llama-index`. Мы пройдем все шаги: от настройки окружения до извлечения структурированных требований и поиска противоречий в документах.\n",
        "\n"
      ],
      "metadata": {
        "id": "MA8CRUWlrKHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Шаг 0: Подготовка рабочего окружения\n",
        "\n",
        "Сначала установим все необходимые библиотеки. Нам понадобятся:\n",
        "- `llama-index`: Основной фреймворк.\n",
        "- `llama-index-llms-groq`: Интеграция с быстрыми и бесплатными моделями от Groq.\n",
        "- `llama-index-embeddings-huggingface`: Для использования бесплатных локальных моделей эмбеддингов.\n",
        "- `pypdf`, `reportlab`: Для работы с PDF-файлами.\n",
        "- `sentence-transformers`: Зависимость для модели эмбеддингов."
      ],
      "metadata": {
        "id": "m1HZWg3QrSW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Устанавливаем библиотеки в \"тихом\" режиме\n",
        "!pip install -q llama-index llama-index-llms-groq llama-index-embeddings-huggingface pypdf reportlab sentence-transformers llama-index-program-openai\n",
        "\n",
        "# Импортируем все необходимые модули\n",
        "import os\n",
        "import shutil\n",
        "from getpass import getpass\n",
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
        "from llama_index.llms.groq import Groq\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.program.openai import OpenAIPydanticProgram # Работает с любой LLM, не только OpenAI\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.pagesizes import letter\n"
      ],
      "metadata": {
        "id": "-EWcolS1rVGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Настройка API ключа\n",
        "\n",
        "Для работы нам понадобится бесплатный API-ключ от Groq.\n",
        "1.  Зайдите на [https://console.groq.com/keys](https://console.groq.com/keys)\n",
        "2.  Создайте и скопируйте бесплатный API-ключ.\n",
        "3.  Вставьте его в поле ввода, которое появится после запуска следующей ячейки."
      ],
      "metadata": {
        "id": "thHREGbHragT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Пожалуйста, введите ваш Groq API ключ:\")\n",
        "groq_api_key = getpass()\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = groq_api_key\n",
        "print(\"✅ Groq API ключ успешно установлен.\")"
      ],
      "metadata": {
        "id": "ZpR5SIaerenH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Шаг 0.1: Настройка моделей (LLM и Embeddings)\n",
        "\n",
        "Теперь мы настроим две ключевые модели в `Settings`, чтобы `llama-index` использовал их по умолчанию:\n",
        "1.  **LLM (Языковая модель):** `llama3-70b-8192` от Groq. Она будет генерировать текст и заполнять наши Pydantic-модели.\n",
        "2.  **Embed Model:** `BAAI/bge-small-en-v1.5` от HuggingFace. Эта модель будет работать **локально** прямо в Colab, чтобы превращать текст в векторы (эмбеддинги) для семантического поиска. Это бесплатно и не требует API-ключей."
      ],
      "metadata": {
        "id": "nziea2J9rjhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Настраиваем LLM от Groq\n",
        "Settings.llm = Groq(model=\"llama-3.3-70b-versatile\", api_key=groq_api_key)\n",
        "\n",
        "# Настраиваем локальную модель для эмбеддингов\n",
        "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "print(\"✅ LLM (Groq) и Embed Model (HuggingFace) успешно настроены.\")"
      ],
      "metadata": {
        "id": "TULxH3ymroIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Шаг 0.5: Создание тестовых документов\n",
        "\n",
        "Чтобы сделать ноутбук полностью самодостаточным, мы программно создадим папку `project_docs` и три файла с \"сырыми\" требованиями, которые наш агент будет анализировать."
      ],
      "metadata": {
        "id": "zrX74GKcrpMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dummy_pdf(file_path, text_content):\n",
        "    \"\"\"Вспомогательная функция для создания простого PDF-файла.\"\"\"\n",
        "    c = canvas.Canvas(file_path, pagesize=letter)\n",
        "    width, height = letter\n",
        "    text_object = c.beginText(50, height - 50); text_object.setFont(\"Helvetica\", 12)\n",
        "    for line in text_content.split('\\n'): text_object.textLine(line)\n",
        "    c.drawText(text_object); c.save()\n",
        "\n",
        "# Контент для наших документов\n",
        "pdf_content = \"Проект: Smart Notes App. Описание: Приложение для создания и управления заметками. Пользователи должны иметь возможность делиться своими заметками с другими.\"\n",
        "chat_log_content = \"Алекс: Клиент настаивает на входе через Google. Как пользователь, я хочу иметь возможность делиться заметками, чтобы мои коллеги могли их комментировать.\"\n",
        "features_md_content = \"# План фичей v1.0\\n## Аутентификация\\n- [x] Логин по Email/паролю\\n**Примечание:** На первом этапе делаем только вход по Email.\"\n",
        "\n",
        "# Создаем папку и файлы\n",
        "if os.path.exists(\"project_docs\"): shutil.rmtree(\"project_docs\")\n",
        "os.makedirs(\"project_docs\")\n",
        "create_dummy_pdf(\"project_docs/brief.pdf\", pdf_content)\n",
        "with open(\"project_docs/chat_log.txt\", \"w\", encoding='utf-8') as f: f.write(chat_log_content)\n",
        "with open(\"project_docs/features.md\", \"w\", encoding='utf-8') as f: f.write(features_md_content)\n",
        "\n",
        "print(\"✅ Созданы 3 документа в папке 'project_docs'.\")"
      ],
      "metadata": {
        "id": "7YDeDm-Sr_WO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Шаги 1 и 2: Загрузка и Индексация\n",
        "\n",
        "Теперь самое интересное. Мы используем `SimpleDirectoryReader` для загрузки всех документов из папки. Затем `VectorStoreIndex` превратит их в семантически доступную базу знаний, используя настроенную нами локальную embedding-модель."
      ],
      "metadata": {
        "id": "2q-ezFBgsMdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем все документы из папки\n",
        "documents = SimpleDirectoryReader(\"./project_docs\").load_data()\n",
        "\n",
        "# Создаем векторный индекс. На этом шаге происходит вся \"магия\" векторизации.\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "\n",
        "print(f\"✅ Документы загружены и проиндексированы локально. Создан индекс.\")"
      ],
      "metadata": {
        "id": "xmeR5fQYsPSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Шаг 3: Определение структуры вывода (Pydantic)\n",
        "\n",
        "Мы хотим получать результат не в виде простого текста, а в виде структурированных Python-объектов. Для этого мы описываем \"контракт\" или \"форму\" для LLM с помощью Pydantic-моделей.\n",
        "\n",
        "**Важно:** Каждый класс должен иметь `docstring` (док-строку `\"\"\"...\"\"\"`), чтобы LLM понимала общую цель создаваемого объекта."
      ],
      "metadata": {
        "id": "XarKPvTEsTCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AcceptanceCriterion(BaseModel):\n",
        "    \"\"\"Модель для одного критерия приемки.\"\"\"\n",
        "    criterion: str = Field(description=\"Текст критерия приемки.\")\n",
        "\n",
        "class UserStory(BaseModel):\n",
        "    \"\"\"Модель для полной пользовательской истории с ее критериями.\"\"\"\n",
        "    story: str = Field(description=\"Полный текст User Story в формате 'As a [user], I want [goal], so that [benefit]'.\")\n",
        "    criteria: List[AcceptanceCriterion] = Field(description=\"Список критериев приемки для этой истории.\")\n",
        "\n",
        "class RequirementsAnalysis(BaseModel):\n",
        "    \"\"\"Контейнер данных для хранения результатов анализа требований. Содержит список всех найденных пользовательских историй.\"\"\"\n",
        "    user_stories: List[UserStory] = Field(description=\"Список всех пользовательских историй, найденных в документах.\")\n",
        "\n",
        "print(\"✅ Pydantic-модели определены.\")"
      ],
      "metadata": {
        "id": "ARbNRgOKsUN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WOW-МОМЕНТ 1: Извлечение User Stories - Попытка №1 (Наивный подход)\n",
        "\n",
        "Сейчас мы попробуем извлечь User Stories, используя \"наивный\" промпт. Мы дадим модели творческую свободу и разрешим ей \"додумывать\" информацию на основе контекста. Давайте посмотрим, что из этого получится."
      ],
      "metadata": {
        "id": "VBNye-dEsi0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Наивный промпт с разрешением \"додумывать\"\n",
        "naive_prompt_template_str = \"\"\"\n",
        "Проанализируй предоставленный контекст из проектных документов.\n",
        "Извлеки все пользовательские истории (user stories) и для каждой из них\n",
        "сформулируй по крайней мере 2-3 релевантных критерия приемки.\n",
        "Если история неполная, додумай ее на основе контекста.\n",
        "\"\"\"\n",
        "\n",
        "# Создаем программу с наивным промптом\n",
        "naive_program = OpenAIPydanticProgram.from_defaults(\n",
        "    output_cls=RequirementsAnalysis,\n",
        "    prompt_template_str=naive_prompt_template_str,\n",
        "    llm=Settings.llm,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Извлекаем релевантный контекст\n",
        "query_engine = index.as_query_engine()\n",
        "retrieved_nodes = query_engine.retrieve(\"Все пользовательские истории и требования\")\n",
        "context_str = \"\\n\\n\".join([n.get_content() for n in retrieved_nodes])\n",
        "\n",
        "# Запускаем программу для извлечения\n",
        "response_naive = naive_program(context_str=context_str)"
      ],
      "metadata": {
        "id": "covWmwnBsj_n",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Результат Попытки №1\n",
        "\n",
        "Выведем результат, который сгенерировала модель."
      ],
      "metadata": {
        "id": "Sk8ssVeWtXAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if response_naive and response_naive.user_stories:\n",
        "    for i, story in enumerate(response_naive.user_stories, 1):\n",
        "        print(f\"История #{i}:\")\n",
        "        print(f\"  - История: {story.story}\")\n",
        "        print(\"  - Критерии приемки:\")\n",
        "        for j, criterion in enumerate(story.criteria, 1):\n",
        "            print(f\"    {j}. {criterion.criterion}\")\n",
        "        print(\"-\" * 20)\n",
        "else:\n",
        "    print(\"Модели не удалось извлечь User Stories.\")"
      ],
      "metadata": {
        "id": "jCiJ10x9tX2r",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Анализ результата: Классическая \"галлюцинация\"!\n",
        "\n",
        "**Обратите внимание!** Модель сгенерировала идеально структурированные User Stories, но их содержание **не имеет ничего общего** с нашими документами про \"Smart Notes App\". Она придумала истории для вымышленного интернет-магазина.\n",
        "\n",
        "**Почему это произошло?**\n",
        "1.  **Слабый контекст:** Наши документы были очень короткими.\n",
        "2.  **Излишняя свобода:** Наш промпт со словом \"додумай\" послужил разрешением на \"творчество\".\n",
        "3.  **Итог:** Не найдя достаточно информации, модель обратилась к своим внутренним знаниям и сгенерировала самый типичный пример, который знает.\n",
        "\n",
        "**Это важнейший урок:** нельзя слепо доверять выводу LLM. Теперь давайте это исправим."
      ],
      "metadata": {
        "id": "qTm8yn5VtZu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WOW-МОМЕНТ 1: Попытка №2 (Строгий промпт-инжиниринг)\n",
        "\n",
        "Теперь мы напишем более строгий промпт. Мы явно **запретим** модели придумывать информацию и потребуем основываться **исключительно** на предоставленном тексте. Это ключевая техника для повышения надежности AI-агентов."
      ],
      "metadata": {
        "id": "Cbrpbf42tc2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Строгий промпт с явными запретами\n",
        "strict_prompt_template_str = \"\"\"\n",
        "Проанализируй предоставленный контекст из проектных документов.\n",
        "Твоя задача — извлечь пользовательские истории (user stories), которые ЯВНО упомянуты в тексте.\n",
        "Для каждой извлеченной истории сформулируй 2-3 релевантных критерия приемки, основываясь СТРОГО на контексте.\n",
        "**ЗАПРЕЩЕНО:** Придумывать или генерировать истории, которых нет в тексте. Если в тексте нет явных user stories, верни пустой список.\n",
        "\"\"\"\n",
        "\n",
        "# Создаем новую программу со строгим промптом\n",
        "strict_program = OpenAIPydanticProgram.from_defaults(\n",
        "    output_cls=RequirementsAnalysis,\n",
        "    prompt_template_str=strict_prompt_template_str,\n",
        "    llm=Settings.llm,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Контекст у нас уже есть из предыдущего шага, можем использовать его повторно\n",
        "response_strict = strict_program(context_str=context_str)"
      ],
      "metadata": {
        "id": "bi9H5LCQtgl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Результат Попытки №2\n",
        "\n",
        "Смотрим, что получилось со строгими правилами."
      ],
      "metadata": {
        "id": "pLie0IsHtjPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if response_strict and response_strict.user_stories:\n",
        "    for i, story in enumerate(response_strict.user_stories, 1):\n",
        "        print(f\"История #{i}:\")\n",
        "        print(f\"  - История: {story.story}\")\n",
        "        print(\"  - Критерии приемки:\")\n",
        "        for j, criterion in enumerate(story.criteria, 1):\n",
        "            print(f\"    {j}. {criterion.criterion}\")\n",
        "        print(\"-\" * 20)\n",
        "else:\n",
        "    print(\"✅ Модель не нашла явных User Stories в тексте. Это ПРАВИЛЬНЫЙ результат, так как она последовала нашему запрету на галлюцинации.\")"
      ],
      "metadata": {
        "id": "Ig5rCvUNtkov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WOW-МОМЕНТ 2: Поиск противоречий\n",
        "\n",
        "Теперь, когда мы научились контролировать агента, перейдем к аналитической задаче. Мы попросим его найти конфликты в требованиях, используя обычный текстовый запрос."
      ],
      "metadata": {
        "id": "BPnP-A1Ctns6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_query_engine = index.as_query_engine()\n",
        "\n",
        "contradiction_prompt = \"\"\"\n",
        "Внимательно сравни требования к процессу аутентификации пользователя из всех документов.\n",
        "Существуют ли между ними какие-либо противоречия?\n",
        "Если да, четко опиши, в чем заключается противоречие, и укажи, в каких документах содержится конфликтующая информация.\n",
        "\"\"\"\n",
        "\n",
        "response_text = text_query_engine.query(contradiction_prompt)"
      ],
      "metadata": {
        "id": "UEy49-jwtofX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Результат (аналитический ответ)"
      ],
      "metadata": {
        "id": "NTMPoeQBtsCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_text)"
      ],
      "metadata": {
        "id": "dcMIFaNHttUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Практическое задание для самостоятельной работы\n",
        "\n",
        "## Легенда\n",
        "\n",
        "Прошла неделя после вашего анализа. Клиенту очень понравился ваш подход к автоматическому извлечению требований, и он считает его \"магией\". Вдохновившись, он прислал вам новую порцию документов с уточнениями к первому спринту и идеями для второго.\n",
        "\n",
        "Ваша задача — обновить и расширить вашего \"Агента-Аналитика\", чтобы обработать новые данные, извлечь из них еще больше полезной информации и подготовить сводку для команды разработки.\n",
        "\n",
        "---\n",
        "\n",
        "## Входные данные (Новые документы от клиента)\n",
        "\n",
        "Вам необходимо программно создать новую папку `project_docs_sprint2` и поместить в нее три новых файла со следующим содержимым:\n",
        "\n",
        "### 1. `meeting_minutes.txt` (Протокол встречи)\n",
        "```text\n",
        "Обсуждение фичей 2-го спринта.\n",
        "Ключевое: пользователи жалуются, что в заметках сложно ориентироваться. Предлагаю добавить систему тегов. Пользователь должен иметь возможность прикрепить к заметке несколько тегов (например, #работа, #идеи) и потом фильтровать все заметки по этим тегам. Это главная фича.\n",
        "Мария: Хорошая идея. Также клиент упомянул, что хотел бы иметь возможность экспортировать все свои данные в JSON-файл в один клик, чтобы не бояться их потерять.\n",
        "```\n",
        "\n",
        "### 2. `feature_update_email.md` (Письмо от менеджера)\n",
        "```markdown\n",
        "### Обновление по аутентификации\n",
        "\n",
        "Привет! Мы обсудили с клиентом противоречие, которое ты нашел. Он решил, что нам нужны ОБА способа входа.\n",
        "\n",
        "**ИТОГО:** Система должна поддерживать вход как через **Google**, так и через **Email/пароль**. Это требование с высоким приоритетом.\n",
        "```\n",
        "\n",
        "### 3. `technical_constraints.pdf` (Технические ограничения)\n",
        "*Используйте функцию `create_dummy_pdf` из ноутбука, чтобы создать PDF-файл с этим текстом:*\n",
        "```text\n",
        "Нефункциональные требования (НФТ):\n",
        "1. Безопасность: Система должна соответствовать базовым принципам GDPR. Все пользовательские данные должны храниться в зашифрованном виде.\n",
        "2. Производительность: Время ответа на любой запрос пользователя не должно превышать 500 миллисекунд.\n",
        "```\n",
        "---\n",
        "\n",
        "## Ваша задача\n",
        "\n",
        "**1. Адаптация кода:**\n",
        "*   Модифицируйте код из лекции, чтобы он читал документы из новой папки `project_docs_sprint2`.\n",
        "\n",
        "**2. Расширение модели данных (Pydantic):**\n",
        "*   Ваша текущая модель `RequirementsAnalysis` умеет извлекать только User Stories. Вам нужно ее расширить, чтобы она могла хранить и другие типы требований.\n",
        "*   Создайте новую Pydantic-модель `NonFunctionalRequirement` с полями `requirement: str` и `category: str` (например, \"Безопасность\", \"Производительность\").\n",
        "*   Добавьте в основную модель `RequirementsAnalysis` два новых поля:\n",
        "    *   `nfrs: List[NonFunctionalRequirement]` для хранения списка нефункциональных требований.\n",
        "    *   `updates_summary: str` для хранения краткой сводки об изменениях.\n",
        "\n",
        "**3. Промпт-инжиниринг (самая важная часть!):**\n",
        "*   Напишите **новый, комплексный промпт** для вашей Pydantic-программы. Этот промпт должен давать агенту команду извлечь из всех документов **сразу три типа информации за один вызов**:\n",
        "    1.  Все **User Stories** (включая новые, про теги и экспорт).\n",
        "    2.  Все **нефункциональные требования** (про GDPR и производительность).\n",
        "    3.  Краткую **сводку (summary)** об основных изменениях в требованиях (например, про обновление логики аутентификации).\n",
        "\n",
        "**4. Запуск и анализ:**\n",
        "*   Запустите обновленный код.\n",
        "*   Проанализируйте полученный структурированный вывод. Удалось ли агенту корректно извлечь всю информацию?\n",
        "\n",
        "---\n",
        "## Что нужно сдать на проверку\n",
        "\n",
        "1.  **Python-скрипт (`.py`) или ноутбук (`.ipynb`)** с вашим финальным кодом.\n",
        "2.  **Финальный вывод агента** (скопированный структурированный текст или JSON).\n",
        "3.  **Краткий анализ (1-2 абзаца) в файле `analysis.txt` или в Markdown-ячейке ноутбука**:\n",
        "    *   Опишите, как вы изменили Pydantic-модель и промпт.\n",
        "    *   Оцените, насколько хорошо агент справился с задачей. Нашел ли он все требования? Были ли ошибки или \"галлюцинации\"?\n",
        "    *   Какие улучшения вы бы предложили для дальнейшей работы агента?"
      ],
      "metadata": {
        "id": "P8qvNbtHx1qq"
      }
    }
  ]
}